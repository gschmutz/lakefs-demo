{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1dc880-4597-4ee7-aee8-9a24ccfce50c",
   "metadata": {},
   "source": [
    "<img src=\"https://store-images.s-microsoft.com/image/apps.22094.728e1f25-a784-458f-90e1-7729049edba2.144bf785-b784-41dd-bcef-c91792108c09.f0be1bc2-af8f-49fc-ac4c-dfd9d53d9e8d\" alt=\"lakeFS logo\" width=130/> \n",
    "\n",
    "# Running data quality checks with lakeFS web hooks\n",
    "\n",
    "_This notebook shows how to use [lakeFS Hooks](https://docs.lakefs.io/hooks/overview.html)_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45631bda-4836-4247-951b-216cf32b2edd",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "To use this demo you need to have a webhook server running that is accessible from your lakeFS server. The provided action assumes that it's called `lakefs-hooks` - if it's on a different host or IP then amend the `./hooks/actions.yaml` file. \n",
    "\n",
    "If you're using the lakeFS-samples Docker Compose to run lakeFS you can spin up a webhook server by doing the following: \n",
    "\n",
    "1. Clone the repository\n",
    "\n",
    "    ```\n",
    "    git clone https://github.com/treeverse/lakeFS-hooks.git\n",
    "    cd lakeFS-hooks\n",
    "    ```\n",
    "    \n",
    "2. Run the webhook server and attach it to the lakeFS network    \n",
    "\n",
    "    ```bash\n",
    "    docker build -t lakefs-hooks .\n",
    "    \n",
    "    docker run --rm \\\n",
    "               --network=bagel \\\n",
    "               -e LAKEFS_SERVER_ADDRESS=http://lakefs:8000 \\\n",
    "               -e LAKEFS_ACCESS_KEY_ID=AKIAIOSFOLKFSSAMPLES \\\n",
    "               -e LAKEFS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \\\n",
    "               --name lakefs-hooks \\\n",
    "               lakefs-hooks\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a2d5d-5850-4ab3-b5b6-e011ac823504",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134ad6b-27a1-4967-80d8-80bb2e931ebb",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53ac2ca6-74dd-4a8b-bd69-01d1a11b4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsExternalEndpoint = 'http://lakefs:28220'\n",
    "lakefsAccessKey = 'V42FCGRVMK24JJ8DHUYG'\n",
    "lakefsSecretKey = 'bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88179981-2829-4a08-8a55-d7fc4b3d4a4e",
   "metadata": {},
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6455ff12-4ec4-4186-b4fb-f312be22972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageNamespace = 's3://lakefs-demo-bucket' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa407b-ca36-4537-bbb8-12be86359c13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52764a-9e08-46c6-8b20-7c457ef327e2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fea6e45c-5c2c-43ae-8e66-cf5f799691df",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941601dd-6e92-48b8-ac34-dcb6f50f6b52",
   "metadata": {},
   "source": [
    "### Create lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d65b75b2-d0d2-4b32-b755-6f68016d8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292d908-8e04-4db9-a298-c5a367cb36b0",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10916a6c-4bb4-44b0-a9f4-66ba37b978d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying lakeFS credentials‚Ä¶\n",
      "‚Ä¶‚úÖlakeFS credentials verified\n",
      "\n",
      "‚ÑπÔ∏èlakeFS version 1.43.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.config.get_config()\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v['version_config']['version']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4f16b-1216-4f5a-a8e0-e18772e0619e",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca54a727-14ed-4766-b120-76766aa6f470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing repo demo using storage namespace s3://lakefs-demo-bucket/demo\n"
     ]
    }
   ],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023e488-ad7f-44c3-9f30-404d5037b81c",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41b22768-bc8f-4abe-a799-ee6c5bf54d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lakeFS / Jupyter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff701d4f10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f21c5c4-e4eb-4958-b2ec-f514ea8854e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_branch = \"ingest-landing-area\"\n",
    "staging_branch = \"staging-area\"\n",
    "prod_branch = \"main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e812ce3-7ba9-4e87-8c04-8b2f78dfb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96b574-e57c-49aa-99c2-982d39ddad5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf68f1e-170c-4390-bf7b-c7f45815c847",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c62c9-6290-4ec7-bb5f-4ef00e4dcf32",
   "metadata": {},
   "source": [
    "## Creating Ingest and Staging branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06471788-fc77-4704-a08f-9b614e81ea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pagination': {'has_more': False,\n",
       "                'max_per_page': 1000,\n",
       "                'next_offset': '',\n",
       "                'results': 1},\n",
       " 'results': [{'commit_id': 'fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7',\n",
       "              'id': 'main'}]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.list_branches(repo_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9866be30-18c6-40a6-8d47-0bcdfd5218c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=ingest_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27ee1f69-3865-4c9f-88a8-1f17b0ead04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=staging_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "225faff0-d1cd-42dc-a21d-ff801491d57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pagination': {'has_more': False,\n",
       "                'max_per_page': 1000,\n",
       "                'next_offset': '',\n",
       "                'results': 3},\n",
       " 'results': [{'commit_id': 'fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7',\n",
       "              'id': 'ingest-landing-area'},\n",
       "             {'commit_id': 'fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7',\n",
       "              'id': 'main'},\n",
       "             {'commit_id': 'fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7',\n",
       "              'id': 'staging-area'}]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.list_branches(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca6b494-c4fc-4b8a-9a92-50073da2ad77",
   "metadata": {},
   "source": [
    "## Uploading movies data to ingest branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6eb7a96-4fa4-40c4-943a-18d0b865c646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dt=2024-11-25/movies.csv'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest_data = \"movies.csv\"\n",
    "\n",
    "ingest_path = f'dt={str(date.today())}/{ingest_data}'\n",
    "ingest_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "709bd779-9d9e-4715-bd56-63434c514095",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{ingest_data}', 'rb') as f:\n",
    "    lakefs.objects.upload_object(repository=repo_name, \n",
    "                                 branch=ingest_branch, \n",
    "                                 path=ingest_path, \n",
    "                                 content=f\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbd97fd2-b005-464e-827e-e4a58eb5b50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'dt=2024-11-25/movies.csv',\n",
       "  'path_type': 'object',\n",
       "  'size_bytes': 1071619,\n",
       "  'type': 'added'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.diff_branch(repository=repo_name, \n",
    "                            branch=ingest_branch).results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a33e0ed6-3fb9-406c-9e1a-47038e29f87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'quickstart',\n",
       " 'creation_date': 1732537505,\n",
       " 'generation': 2,\n",
       " 'id': '82e78cef3753024613d2a6677638720935f8d231746ad0f4ffa80d1878ea11a3',\n",
       " 'message': \"netflix movie data arrived at landing area (today's partition)\",\n",
       " 'meta_range_id': 'c45763dbf7189efbc3e6c6c5a9853d8351fdb8bd0243ef1932d7858659610000',\n",
       " 'metadata': {},\n",
       " 'parents': ['fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7'],\n",
       " 'version': 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=ingest_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"netflix movie data arrived at landing area (today's partition)\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c20972-6522-4e19-8fcb-ee523999e79d",
   "metadata": {},
   "source": [
    "## Uploading actions.yaml config file to staging branch\n",
    "\n",
    "* We want to run data quality tests on staging branch before merging the data into production. Hooks config file `actions.yaml` needs to be in the branch on which the tests are run.\n",
    "\n",
    "* So add `_lakefs_actions/actions.yaml` to staging branch\n",
    "* `actions.yaml` contains a pre-merge hook configured to check for file format validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45b43f57-2e67-4858-bda6-3d3e23395d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks_config_yaml = \"actions.yaml\"\n",
    "hooks_prefix = \"_lakefs_actions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2fa4a6f8-164a-40d9-ba52-00023847c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./hooks/{hooks_config_yaml}', 'rb') as f:\n",
    "    lakefs.objects.upload_object(repository=repo_name, \n",
    "                                 branch=staging_branch, \n",
    "                                 path=f'{hooks_prefix}/{hooks_config_yaml}', \n",
    "                                 content=f\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d38645d-24a5-4672-ae36-6192cc3fafc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': '_lakefs_actions/actions.yaml',\n",
       "  'path_type': 'object',\n",
       "  'size_bytes': 420,\n",
       "  'type': 'added'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.diff_branch(repository=repo_name, \n",
    "                            branch=staging_branch).results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea5e6b70-cb0d-4eb6-b054-40981ebbc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'quickstart',\n",
       " 'creation_date': 1732537507,\n",
       " 'generation': 2,\n",
       " 'id': '9edb469e859e3fa21fbed74150b8f05eecdeaf75c9bfe072b44163823e593685',\n",
       " 'message': 'Added hooks config file - actions.yaml to staging area',\n",
       " 'meta_range_id': '97c08afe9761482f9edfd6283c249e80c717dc0d0d2e052347e2b7de5dae5fef',\n",
       " 'metadata': {},\n",
       " 'parents': ['fe7d63abe38d39291e4d506a9bf43954c2a1924ef4146411323c5facfa2843c7'],\n",
       " 'version': 1}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message='Added hooks config file - actions.yaml to staging area')\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ddad0-b760-41e6-8874-14d8d431b8e0",
   "metadata": {},
   "source": [
    "## Extracting data from ingest branch for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8130050b-b99c-43f6-822e-5819ae02b76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://demo/ingest-landing-area/dt=2024-11-25/movies.csv'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest_long_path = f\"s3a://{repo_name}/{ingest_branch}/{ingest_path}\"\n",
    "ingest_long_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ad53b14-9d89-4bb3-8c3d-48aa9ed32e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8791\n",
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(ingest_long_path)\n",
    "print(movies_df.count())\n",
    "print(movies_df.printSchema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40fb8048-959b-486b-b2f3-2063781c6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+-------------------+--------------+----------+------------+------+---------+--------------------+\n",
      "|show_id|   type|               title|           director|       country|date_added|release_year|rating| duration|           listed_in|\n",
      "+-------+-------+--------------------+-------------------+--------------+----------+------------+------+---------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|    Kirsten Johnson| United States| 9/25/2021|        2020| PG-13|   90 min|       Documentaries|\n",
      "|     s3|TV Show|           Ganglands|    Julien Leclercq|        France| 9/24/2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|\n",
      "|     s6|TV Show|       Midnight Mass|      Mike Flanagan| United States| 9/24/2021|        2021| TV-MA| 1 Season|TV Dramas, TV Hor...|\n",
      "|    s14|  Movie|Confessions of an...|      Bruno Garotti|        Brazil| 9/22/2021|        2021| TV-PG|   91 min|Children & Family...|\n",
      "|     s8|  Movie|             Sankofa|       Haile Gerima| United States| 9/24/2021|        1993| TV-MA|  125 min|Dramas, Independe...|\n",
      "|     s9|TV Show|The Great British...|    Andy Devonshire|United Kingdom| 9/24/2021|        2021| TV-14|9 Seasons|British TV Shows,...|\n",
      "|    s10|  Movie|        The Starling|     Theodore Melfi| United States| 9/24/2021|        2021| PG-13|  104 min|    Comedies, Dramas|\n",
      "|   s939|  Movie|Motu Patlu in the...|        Suhas Kadav|         India|  5/1/2021|        2019| TV-Y7|   87 min|Children & Family...|\n",
      "|    s13|  Movie|        Je Suis Karl|Christian Schwochow|       Germany| 9/23/2021|        2021| TV-MA|  127 min|Dramas, Internati...|\n",
      "|   s940|  Movie|Motu Patlu in Won...|        Suhas Kadav|         India|  5/1/2021|        2013| TV-Y7|   76 min|Children & Family...|\n",
      "+-------+-------+--------------------+-------------------+--------------+----------+------------+------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "814342d2-dc6b-40f1-b0c2-f7668c3269f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.sample(False,0.1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c094484-6259-4cf2-9b9b-e6ea94e35ba0",
   "metadata": {},
   "source": [
    "## Loading transformed data into Staging Area/Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "acf34348-7428-445d-92bb-dfb425369b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://demo/staging-area'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_long_path = f\"s3a://{repo_name}/{staging_branch}\"\n",
    "staging_long_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761563d0-f709-4cdd-bfe3-8a7ebc23bf1e",
   "metadata": {},
   "source": [
    "## Scenario #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefc1a8-e18f-499b-b64d-f731704ec7ba",
   "metadata": {},
   "source": [
    "### Writing parquet files to staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "414a8177-4592-4e79-8daf-04da865fe99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .partitionBy(\"type\")\\\n",
    "        .mode(\"append\")\\\n",
    "        .parquet(f\"{staging_long_path}/analytics/movies-by-type-parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65c087b0-cc80-42ea-87d1-0468db60be5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'quickstart',\n",
       " 'creation_date': 1732537515,\n",
       " 'generation': 3,\n",
       " 'id': '5c535bdaecb82574c17854f5246a3fbe00ef52a0f92020cfdfadb41ce122e1c0',\n",
       " 'message': 'loaded paritioned movies parquet to staging area',\n",
       " 'meta_range_id': '2b64429d3e506103040c880515d4d6ac1725836582ae5c8e4bbbad80103312bd',\n",
       " 'metadata': {},\n",
       " 'parents': ['9edb469e859e3fa21fbed74150b8f05eecdeaf75c9bfe072b44163823e593685'],\n",
       " 'version': 1}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message='loaded paritioned movies parquet to staging area'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b1e25-1909-41e1-94c6-c2a3d179d022",
   "metadata": {},
   "source": [
    "### Pushing parquet files to Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f73ed3b-fcdf-4ae7-9e1b-06a1655e048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': '68db0d9b06e3c8bf3a7a8ba596a007de0087d871b11da1cad0bf4bbebdac6549'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.refs.merge_into_branch(repository=repo_name, \n",
    "                              source_ref=staging_branch, \n",
    "                              destination_branch=prod_branch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2ee22-0397-40df-a199-deb2b3fe6055",
   "metadata": {},
   "source": [
    "### Writing csv files to staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "478f146a-be0b-4685-8f9b-1d2606368df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .partitionBy(\"type\")\\\n",
    "        .mode(\"append\")\\\n",
    "        .csv(f\"{staging_long_path}/analytics/movies-by-type-csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5a5718b-8d16-4641-a1ff-96b6dcd02400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'quickstart',\n",
       " 'creation_date': 1732537541,\n",
       " 'generation': 4,\n",
       " 'id': 'dfe8723f124918feddbfbf50bb821e13bc19b31e521b388362b19acf9f8a7d73',\n",
       " 'message': 'loaded paritioned movies csv to staging area',\n",
       " 'meta_range_id': 'ca97bf1da24d1f1576bf764e4809ab42404052640120e46e12f16cf492bcbf3d',\n",
       " 'metadata': {},\n",
       " 'parents': ['5c535bdaecb82574c17854f5246a3fbe00ef52a0f92020cfdfadb41ce122e1c0'],\n",
       " 'version': 1}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message='loaded paritioned movies csv to staging area'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198eac3e-358e-4437-9ca0-1608ab2599e5",
   "metadata": {},
   "source": [
    "### Pushing csv files to Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d5d7f89-7116-4123-8c77-eaff33d39c3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiException",
     "evalue": "(412)\nReason: Precondition Failed\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'X-Request-Id': '3e2c6ff1-5799-4b35-90c6-a4efb32344a3', 'Date': 'Mon, 25 Nov 2024 12:26:02 GMT', 'Content-Length': '186'})\nHTTP response body: {\"message\":\"1 error occurred:\\n\\t* hook run id '0000_0000' failed on action 'ParquetOnlyInProduction' hook 'production_format_validator': webhook request failed (status code: 400)\\n\\n\"}\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlakefs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_into_branch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepository\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msource_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstaging_branch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdestination_branch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprod_branch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/api/refs_api.py:698\u001b[0m, in \u001b[0;36mRefsApi.merge_into_branch\u001b[0;34m(self, repository, source_ref, destination_branch, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_ref\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    695\u001b[0m     source_ref\n\u001b[1;32m    696\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination_branch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    697\u001b[0m     destination_branch\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_into_branch_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/api_client.py:835\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m         header_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    832\u001b[0m             content_type_headers_list)\n\u001b[1;32m    833\u001b[0m         params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m header_list\n\u001b[0;32m--> 835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/api_client.py:409\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    418\u001b[0m                                                method, path_params,\n\u001b[1;32m    419\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m                                                _request_timeout,\n\u001b[1;32m    428\u001b[0m                                                _host, _check_type))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/api_client.py:203\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    207\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/api_client.py:196\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    192\u001b[0m     url \u001b[38;5;241m=\u001b[39m _host \u001b[38;5;241m+\u001b[39m resource_path\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/api_client.py:455\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    448\u001b[0m                                     query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    449\u001b[0m                                     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m                                     _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    453\u001b[0m                                     body\u001b[38;5;241m=\u001b[39mbody)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(url,\n\u001b[1;32m    464\u001b[0m                                 query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    465\u001b[0m                                 headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m                                 _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    469\u001b[0m                                 body\u001b[38;5;241m=\u001b[39mbody)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/rest.py:267\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, post_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m          body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/lakefs_client/rest.py:226\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mApiException\u001b[0m: (412)\nReason: Precondition Failed\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'X-Request-Id': '3e2c6ff1-5799-4b35-90c6-a4efb32344a3', 'Date': 'Mon, 25 Nov 2024 12:26:02 GMT', 'Content-Length': '186'})\nHTTP response body: {\"message\":\"1 error occurred:\\n\\t* hook run id '0000_0000' failed on action 'ParquetOnlyInProduction' hook 'production_format_validator': webhook request failed (status code: 400)\\n\\n\"}\n\n"
     ]
    }
   ],
   "source": [
    "lakefs.refs.merge_into_branch(repository=repo_name, \n",
    "                              source_ref=staging_branch, \n",
    "                              destination_branch=prod_branch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f411f-451b-4810-8f50-f81ba1ac86ff",
   "metadata": {},
   "source": [
    "### Why did the merge operation fail?\n",
    "If you look deeper into the error log, you'll see that the merge request failed with status code '412' (precondition failed). The actions file was executed and blocked a commit with a csv file to merge into main.\n",
    "\n",
    "## Action execution history\n",
    "\n",
    "üëâüèª You can see previous actions run [here](http://localhost:8000/repositories/hooks-demo-01/actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733e791-98b3-4d49-9bc7-f8c7aac32bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
