# =======================================================================
# Platform Name            lakefs-platform
# Platform Stack:          trivadis/platys-modern-data-platform
# Platform Stack Version:  develop
# =======================================================================
networks:
  default:
    name: lakefs-platform
services:
  #  ================================== Apache Spark 2.x ========================================== #
  spark-master:
    image: bitnami/spark:3.5.3
    container_name: spark-master
    hostname: spark-master
    labels:
      com.platys.name: spark
      com.platys.description: Spark Master Node
      com.platys.webui.title: Spark UI
      com.platys.webui.url: http://dataplatform:28304
    ports:
      - 28304:28304
      - 6066:6066
      - 7077:7077
      - 4040-4044:4040-4044
    environment:
      # bitnami env vars
      SPARK_MODE: master
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
      # spark standard env vars
      SPARK_MASTER_WEBUI_PORT: 28304
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      # env vars for config files
#     INIT_DAEMON_STEP: setup_spark
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://lakefs:8000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_access_key: ${PLATYS_AWS_ACCESS_KEY:-admin}
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_secret_key: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_defaultFS: s3a://demo/main
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://demo/main/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_sql_hive_metastore_jars: builtin
      # SPARK_DEFAULTS_CONF_spark_sql_hive_metastore_version: 3.1.2    
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: in-memory
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: ''
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      # specifies the JARs to be downloaded to the jars folder by maven-download-sh script
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-spark_2.12:3.2.1,io.delta:delta-storage:3.2.1,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,io.lakefs:lakefs-iceberg:0.1.4,io.lakefs:lakefs-spark-extensions_2.12:0.0.3,org.apache.hudi:hudi-spark3.4-bundle_2.12:0.15.0'
      SPARK_DEFAULTS_CONF_spark_jars: /opt/bitnami/spark/jars/delta-spark_2.12-3.2.1.jar,/opt/bitnami/spark/jars/delta-storage-3.2.1.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      # the 3 conf files are mapped to conf.default folder, they are copied with env variable interpolation into conf upon start of container
      - ./conf/spark/hive-site.xml:/opt/bitnami/spark/conf.default/hive-site.xml
      - ./conf/spark/spark-defaults.conf:/opt/bitnami/spark/conf.default/spark-defaults.conf
      - ./init/spark:/docker-entrypoint-initdb.d
      - ./scripts/docker/maven-download.sh:/maven-download.sh
      - ./scripts/spark/pyspark:/opt/bitnami/spark/bin/pyspark
      - ./container-volume/spark/logs/:/var/log/spark/logs
#      - ./scripts/docker/maven-download.sh:/usr/src/app/maven-download.sh
      - spark-3-5-3-vol:/opt/bitnami/spark
    restart: unless-stopped
    healthcheck:
      test: [CMD, spark-submit, --version]
      interval: 30s
      timeout: 10s
      retries: 5
  spark-worker-1:
    image: bitnami/spark:3.5.3
    container_name: spark-worker-1
    hostname: spark-worker-1
    labels:
      com.platys.name: spark
      com.platys.description: Spark Worker Node
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - 28111:28111
    environment:
      # bitnami env vars
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
      # spark standard env vars
      SPARK_WORKER_WEBUI_PORT: '28111'
      SPARK_WORKER_OPTS: -Dspark.worker.cleanup.enabled=true
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      # env vars for config files
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://lakefs:8000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_access_key: ${PLATYS_AWS_ACCESS_KEY:-admin}
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_secret_key: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_defaultFS: s3a://demo/main
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://demo/main/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_sql_hive_metastore_jars: builtin
      # SPARK_DEFAULTS_CONF_spark_sql_hive_metastore_version: 3.1.2    
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: in-memory
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: ''
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      # specifies the JARs to be downloaded to the jars folder by maven-download-sh script
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-spark_2.12:3.2.1,io.delta:delta-storage:3.2.1,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,io.lakefs:lakefs-iceberg:0.1.4,io.lakefs:lakefs-spark-extensions_2.12:0.0.3,org.apache.hudi:hudi-spark3.4-bundle_2.12:0.15.0'
      SPARK_DEFAULTS_CONF_spark_jars: /opt/bitnami/spark/jars/delta-spark_2.12-3.2.1.jar,/opt/bitnami/spark/jars/delta-storage-3.2.1.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/spark/hive-site.xml:/opt/bitnami/spark/conf.default/hive-site.xml
      - ./conf/spark/spark-defaults.conf:/opt/bitnami/spark/conf.default/spark-defaults.conf
      - ./init/spark:/docker-entrypoint-initdb.d
      - ./scripts/docker/maven-download.sh:/maven-download.sh
      - ./container-volume/spark/logs/:/var/log/spark/logs
    restart: unless-stopped
  #  ================================== Jupyter ========================================== #
  jupyter:
    image: quay.io/jupyter/pyspark-notebook:spark-3.5.3
    container_name: jupyter
    hostname: jupyter
    labels:
      com.platys.name: jupyter
      com.platys.description: Web-based interactive development environment for notebooks, code, and data
      com.platys.webui.title: Jupyter UI
      com.platys.webui.url: http://dataplatform:28888
      com.platys.password.envvars: PLATYS_JUPYTER_TOKEN,PLATYS_AWS_SECRET_ACCESS_KEY
    ports:
      - 28888:8888
      - 28376-28380:4040-4044
    user: root
    extra_hosts:
      - host.docker.internal:host-gateway
    environment:
      JUPYTER_ENABLE_LAB: "'yes'"
      GRANT_SUDO: "'yes'"
      JUPYTER_TOKEN: ${PLATYS_JUPYTER_TOKEN:-abc123!}
      DOCKER_STACKS_JUPYTER_CMD: lab
      MAVEN_DOWNLOAD_JARS: com.amazonaws:aws-java-sdk-bundle:1.12.262,org.apache.hadoop:hadoop-aws:3.3.4,com.google.guava:guava:27.1-jre
      # remove some JARS if they are conflicting with the ones installed above
      REMOVE_JARS: guava-14.0.1.jar
      # for awscli & s3cmd
      AWS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      AWS_ENDPOINT: http://lakefs:8000
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION: us-east-1
    volumes:
      - ./data-transfer:/data-transfer
      - ./init/jupyter/on-startup-jupyter/:/usr/local/bin/start-notebook.d/
      - ./init/jupyter/on-startup-jupyter-finished/:/usr/local/bin/before-notebook.d/
      - ./init/jupyter/on-startup-notebook-kernel:/home/jovyan/.ipython/profile_default/startup/
      - ./scripts/docker/maven-download.sh:/maven-download.sh
    command:
      # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
      - bash
      - -c
      - |
        start-notebook.sh
    restart: unless-stopped
  #  ================================== Minio ========================================== #
  minio-1:
    image: minio/minio:RELEASE.2025-02-07T23-21-09Z
    container_name: minio-1
    hostname: minio-1
    labels:
      com.platys.name: minio
      com.platys.description: Software-defined Object Storage
      com.platys.webui.title: MinIO UI
      com.platys.webui.url: http://dataplatform:9010
      com.platys.password.envvars: PLATYS_AWS_SECRET_ACCESS_KEY
    ports:
      # S3 API Port
      - 9000:9000
      # UI Port
      - 9010:9010
    environment:
      MINIO_ROOT_USER: ${PLATYS_AWS_ACCESS_KEY:-admin}
      MINIO_ROOT_PASSWORD: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      # remove region due to problems with RisingWave
      #MINIO_REGION_NAME: us-east-1
      #MINIO_REGION: us-east-1
      MINIO_DOMAIN: minio
      MINIO_SERVER_URL: http://${PUBLIC_IP}:9000
      MINIO_COMPRESSION_ENABLE: off
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_PROMETHEUS_URL: http://prometheus-1:9090
    volumes:
      - ./data-transfer:/data-transfer
    command: server /data --console-address ":9010"
    restart: unless-stopped
    healthcheck:
      test: [CMD, curl, -f, http://minio-1:9000/minio/health/live]
      interval: 15s
      timeout: 20s
      retries: 3
  #  ================================== Minio MC ========================================== #
  minio-mc:
    image: minio/mc:latest
    container_name: minio-mc
    hostname: minio-mc
    labels:
      com.platys.name: minio
      com.platys.description: MinIO Console
    environment:
      # these two env variables are also needed for the s3-credentials.properties file gen to work! 
      AWS_ACCESS_KEY: ${PLATYS_AWS_ACCESS_KEY:-admin}
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      MC_HOST_minio-1: http://${PLATYS_AWS_ACCESS_KEY:-admin}:${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}@minio-1:9000
    volumes:
      - ./data-transfer:/data-transfer
      - ./scripts/docker/wait-for-it.sh:/usr/src/app/wait-for-it.sh
      - ./security/aws/credentials:/tmp/credentials.templ
      - aws-credentials-vol:/tmp/.aws:RO
    entrypoint:
      - /bin/sh
      - -c
      - |
        /usr/src/app/wait-for-it.sh -t 180 minio-1:9000
        mkdir -p /tmp/.aws
        eval "echo \"$$(cat /tmp/credentials.templ)\"" >> /tmp/.aws/credentials
        mc mb --ignore-existing minio-1/demo/main
              for bucket in $$(tr ',' '\n' <<< "lakefs-demo-bucket")
        do
          mc mb --ignore-existing minio-1/$$bucket
        done
        #
        while [ 1 -eq 1 ];do sleep 60;done
    restart: unless-stopped
  #  ================================== Filestash ========================================== #
  filestash:
    image: machines/filestash:latest
    platform: linux/amd64
    container_name: filestash
    hostname: filestash
    labels:
      com.platys.name: filestash
      com.platys.description: Dropbox-like file manager
      com.platys.webui.title: Filestash UI
      com.platys.webui.url: http://dataplatform:28192
    ports:
      - 28192:8334
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/filestash/config.json:/app/data/state/config/config.json
    restart: unless-stopped
  #  ================================== Awscli ========================================== #
  awscli:
    image: trivadis/awscli-s3cmd:latest
    container_name: awscli
    hostname: awscli
    labels:
      com.platys.name: awscli
      com.platys.description: AWS CLI
    environment:
      AWS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      AWS_ENDPOINT: lakefs:8000
      AWS_DEFAULT_REGION: us-east-1
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/awscli/s3cfg.template:/root/.s3cfg.template
    command: tail -f /dev/null
    restart: unless-stopped
  #  ================================== LakeFS ========================================== #
  lakefs:
    image: treeverse/lakefs:1
    container_name: lakefs
    hostname: lakefs
    labels:
      com.platys.name: lakefs
      com.platys.description: Git-Like Data Version Control
      com.platys.webui.title: LakeFS UI
      com.platys.webui.url: http://dataplatform:28220
      com.platys.restapi.title: LakeFS UI
      com.platys.restapi.url: http://dataplatform:28220/api/v1/repositories
    ports:
      - 28220:8000
    environment:
      # possible config settings can be found here: https://docs.lakefs.io/reference/configuration.html#reference
      LAKEFS_DATABASE_TYPE: local
      LAKEFS_DATABASE_LOCAL_PATH: ~/lakefs/metadata
      LAKEFS_DATABASE_LOCAL_ENABLE_LOGGING: false
      LAKEFS_BLOCKSTORE_TYPE: s3
      LAKEFS_BLOCKSTORE_S3_ENDPOINT: http://minio-1:9000
      LAKEFS_BLOCKSTORE_S3_REGION: us-east-1
      LAKEFS_BLOCKSTORE_S3_DISCOVER_BUCKET_REGION: true
      LAKEFS_BLOCKSTORE_S3_FORCE_PATH_STYLE: 'true'
      LAKEFS_BLOCKSTORE_S3_CREDENTIALS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      LAKEFS_BLOCKSTORE_S3_CREDENTIALS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      LAKEFS_BLOCKSTORE_S3_CREDENTIALS_FILE: ~/lakefs/data
      LAKEFS_BLOCKSTORE_S3_CLIENT_LOG_REQUEST: false
      LAkEFS_BLOCKSTORE_S3_CLIENT_LOG_RETRIES: false
      LAKEFS_UI_ENABLED: true
      LAKEFS_ACTIONS_ENABLED: true
      LAKEFS_ACTIONS_LUA_NET_HTTP_ENABLED: false
      LAKEFS_ACTIONS_ENV_ENABLED: true
      LAKEFS_ACTIONS_ENV_PREFIX: LAKEFSACTION_
      LAKEFS_AUTH_ENCRYPT_SECRET_KEY: some random secret string
      LAKEFS_LOGGING_FORMAT: text
      LAKEFS_LOGGING_LEVEL: INFO
      LAKEFS_LOGGING_AUDIT_LOG_LEVEL: INFO
      LAKEFS_STATS_ENABLED: true
      LAKEFS_USAGE_REPORT_ENABLED: false
      LAKEFS_INSTALLATION_USER_NAME: quickstart
      LAKEFS_INSTALLATION_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      LAKEFS_INSTALLATION_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      LAKECTL_CREDENTIALS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      LAKECTL_SERVER_ENDPOINT_URL: http://${PUBLIC_IP}:28220
    volumes:
      - ./data-transfer:/data-transfer
    entrypoint: [/bin/sh, -c]
    command:
      - |
        lakefs run --local-settings &
        wait-for -t 60 lakefs:8000 -- echo "---- Creating repository ----" &&  \
            lakectl repo create lakefs://demo s3://lakefs-demo-bucket/demo --default-branch main --sample-data || true
        echo "-------- Let's go and have axolotl fun! --------"
        wait
    restart: unless-stopped
  lakectl:
    image: treeverse/lakectl:1
    container_name: lakectl
    hostname: lakectl
    labels:
      com.platys.name: lakefs
      com.platys.description: Git-Like Data Version Control
    environment:
      LAKECTL_CREDENTIALS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      LAKECTL_SERVER_ENDPOINT_URL: http://${PUBLIC_IP}:28220
    volumes:
      - ./data-transfer:/data-transfer
    entrypoint:
      - /bin/sh
      - -c
      - |
        while [ 1 -eq 1 ];do sleep 60;done
    restart: unless-stopped
  #  ================================== markdown-viewer ========================================== #
  markdown-viewer:
    image: dannyben/madness:latest
    container_name: markdown-viewer
    hostname: markdown-viewer
    labels:
      com.platys.name: markdown-viewer
      com.platys.description: Platys Platform homepage viewer
      com.platys.webui.title: Markdown Viewer UI
      com.platys.webui.url: http://dataplatform:80
    ports:
      - 80:3000
    volumes:
      - ./artefacts:/docs
      - ./conf/markdown-viewer/markdown-madness.yml:/docs/.madness.yml
      - ./data-transfer:/data-transfer
    command: server
    restart: unless-stopped
    healthcheck:
      test: [CMD-SHELL, curl -f http://markdown-viewer:3000 || exit 1]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 1m
  markdown-renderer:
    image: trivadis/jinja2-renderer:latest
    container_name: markdown-renderer
    hostname: markdown-renderer
    labels:
      com.platys.name: markdown-renderer
      com.platys.description: Platys Platform homepage rendering
    environment:
      USE_PUBLIC_IP: 'True'
      PUBLIC_IP: ${PUBLIC_IP}
      DOCKER_HOST_IP: ${DOCKER_HOST_IP}
      DATAPLATFORM_HOME: ${DATAPLATFORM_HOME}
      PLATYS_PLATFORM_NAME: lakefs-platform
      PLATYS_PLATFORM_STACK: trivadis/platys-modern-data-platform
      PLATYS_PLATFORM_STACK_VERSION: develop
      PLATYS_COPY_COOKBOOK_DATA: 'True'
      SERVICE_LIST_VERSION: 2
    volumes:
      - ./artefacts/templates:/templates
      - ./artefacts/templates:/scripts
      - .:/variables
      - ./artefacts:/output
      - ./data-transfer:/data-transfer
    init: true
  #  ================================== Platys Modern Data Platform Init Service ========================================== #
  platys-mdp-init:
    image: trivadis/platys-mdp-init:latest
    container_name: platys-mdp-init
    hostname: platys-mdp-init
    environment:
      MC_HOST_minio-1: http://${PLATYS_AWS_ACCESS_KEY:-admin}:${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}@minio-1:9000
      MINIO_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      MINIO_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      MINIO_URL: http://lakefs:8000
      LAKEFS_URL: http://lakefs:8000
      LAKEFS_USER: quickstart
      LAKEFS_CREDENTIALS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      LAKEFS_CREDENTIALS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
    volumes:
      - ./data-transfer:/data-transfer
      - ./init/platys-mdp-init:/docker-entrypoint-init.d/
    init: true
    command: sleep 30
    restart: no
volumes:
  data-transfer-vol:
    name: data_transfer_vol
  aws-credentials-vol:
  spark-3-5-3-vol:
